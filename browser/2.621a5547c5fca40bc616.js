(window.webpackJsonp=window.webpackJsonp||[]).push([[2],{VCtk:function(l,n,u){"use strict";u.r(n);var e=u("keVe"),t=function(){function l(){}return l.prototype.ngOnInit=function(){},l}(),a=function(){function l(){}return l.prototype.ngOnInit=function(){},l}(),i=function(){function l(){}return l.prototype.ngOnInit=function(){},l}(),o=function(){function l(){}return l.prototype.ngOnInit=function(){},l}(),c=function(){function l(){this.class=1}return l.prototype.ngOnInit=function(){},l.prototype.classActive=function(l){this.class=l},l}(),s=function(){},r=u("fYis"),p=u("X+PR"),g=u("TOqr"),d=e.La({encapsulation:0,styles:[[".container[_ngcontent-%COMP%]{max-width:1280px!important}.row[_ngcontent-%COMP%]{width:1280px!important}.title[_ngcontent-%COMP%]{text-align:center;margin-top:96px}.title[_ngcontent-%COMP%]   h2[_ngcontent-%COMP%]{font-family:MADE;font-weight:500;text-transform:uppercase;color:#2782ff;font-size:37px;letter-spacing:5.78px}.products[_ngcontent-%COMP%]{margin-top:112px;margin-bottom:96px}.product[_ngcontent-%COMP%]{background-color:#edf3fc;height:496px;cursor:pointer}.product[_ngcontent-%COMP%]   h3[_ngcontent-%COMP%]{font-family:MADE;font-weight:500;font-size:22px;margin-top:54px;margin-left:48px;display:inline-block;color:#464646;letter-spacing:1.39px}.product[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{font-size:15px;margin-left:48px;margin-top:22px;color:#545454}.product[_ngcontent-%COMP%]   a[_ngcontent-%COMP%]{background-color:#fff;padding:13px 21px;margin-top:24px;margin-left:48px;border-radius:100%;display:inline-block}.product[_ngcontent-%COMP%]   .image-product[_ngcontent-%COMP%]{position:absolute;bottom:0;right:15px}.active[_ngcontent-%COMP%]{background-color:#2782ff}.active[_ngcontent-%COMP%]   h3[_ngcontent-%COMP%], .active[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{color:#fff}.active[_ngcontent-%COMP%]   a[_ngcontent-%COMP%]{color:#fff;background-color:#2c75e6}"]],data:{}});function m(l){return e.db(0,[(l()(),e.Na(0,0,null,null,65,"div",[["class","container"]],null,null,null,null,null)),(l()(),e.Na(1,0,null,null,3,"div",[["class","row"]],null,null,null,null,null)),(l()(),e.Na(2,0,null,null,2,"div",[["class","col-lg-12 title"]],null,null,null,null,null)),(l()(),e.Na(3,0,null,null,1,"h2",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Products"])),(l()(),e.Na(5,0,null,null,60,"div",[["class","row products"]],null,null,null,null,null)),(l()(),e.Na(6,0,null,null,14,"div",[["class","col-lg-3"]],null,null,null,null,null)),(l()(),e.Na(7,0,null,null,13,"div",[],[[8,"className",0]],[[null,"click"]],function(l,n,u){var e=!0;return"click"===n&&(e=!1!==l.component.classActive(1)&&e),e},null,null)),(l()(),e.Na(8,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA SDK"])),(l()(),e.Na(10,0,null,null,5,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Pure face recognition engine"])),(l()(),e.Na(12,0,null,null,0,"br",[],null,null,null,null,null)),(l()(),e.cb(-1,null,[" for server, mobile and"])),(l()(),e.Na(14,0,null,null,0,"br",[],null,null,null,null,null)),(l()(),e.cb(-1,null,[" embedded platforms"])),(l()(),e.Na(16,0,null,null,2,"a",[["routerLink","luna-sdk"]],[[1,"target",0],[8,"href",4]],[[null,"click"]],function(l,n,u){var t=!0;return"click"===n&&(t=!1!==e.Xa(l,17).onClick(u.button,u.ctrlKey,u.metaKey,u.shiftKey)&&t),t},null,null)),e.Ma(17,671744,null,0,p.l,[p.k,p.a,g.h],{routerLink:[0,"routerLink"]},null),(l()(),e.Na(18,0,null,null,0,"i",[["class","fas fa-angle-right"]],null,null,null,null,null)),(l()(),e.Na(19,0,null,null,1,"div",[["class","image-product"]],null,null,null,null,null)),(l()(),e.Na(20,0,null,null,0,"img",[["alt",""],["src","assets/images/-e-luna_sdk.png"]],null,null,null,null,null)),(l()(),e.Na(21,0,null,null,14,"div",[["class","col-lg-3"]],null,null,null,null,null)),(l()(),e.Na(22,0,null,null,13,"div",[],[[8,"className",0]],[[null,"click"]],function(l,n,u){var e=!0;return"click"===n&&(e=!1!==l.component.classActive(2)&&e),e},null,null)),(l()(),e.Na(23,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA PLATFORM"])),(l()(),e.Na(25,0,null,null,5,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Complete biometric data"])),(l()(),e.Na(27,0,null,null,0,"br",[],null,null,null,null,null)),(l()(),e.cb(-1,null,[" management system for large"])),(l()(),e.Na(29,0,null,null,0,"br",[],null,null,null,null,null)),(l()(),e.cb(-1,null,[" scale deployments"])),(l()(),e.Na(31,0,null,null,2,"a",[["routerLink","luna-platform"]],[[1,"target",0],[8,"href",4]],[[null,"click"]],function(l,n,u){var t=!0;return"click"===n&&(t=!1!==e.Xa(l,32).onClick(u.button,u.ctrlKey,u.metaKey,u.shiftKey)&&t),t},null,null)),e.Ma(32,671744,null,0,p.l,[p.k,p.a,g.h],{routerLink:[0,"routerLink"]},null),(l()(),e.Na(33,0,null,null,0,"i",[["class","fas fa-angle-right"]],null,null,null,null,null)),(l()(),e.Na(34,0,null,null,1,"div",[["class","image-product"]],null,null,null,null,null)),(l()(),e.Na(35,0,null,null,0,"img",[["alt",""],["src","assets/images/-e-luna_platform.png"]],null,null,null,null,null)),(l()(),e.Na(36,0,null,null,14,"div",[["class","col-lg-3"]],null,null,null,null,null)),(l()(),e.Na(37,0,null,null,13,"div",[],[[8,"className",0]],[[null,"click"]],function(l,n,u){var e=!0;return"click"===n&&(e=!1!==l.component.classActive(3)&&e),e},null,null)),(l()(),e.Na(38,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["FACE.DJ"])),(l()(),e.Na(40,0,null,null,5,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Still and animated 3D avatar"])),(l()(),e.Na(42,0,null,null,0,"br",[],null,null,null,null,null)),(l()(),e.cb(-1,null,[" from a single 2D face image"])),(l()(),e.Na(44,0,null,null,0,"br",[],null,null,null,null,null)),(l()(),e.cb(-1,null,[" creation engine"])),(l()(),e.Na(46,0,null,null,2,"a",[["routerLink","face-dj"]],[[1,"target",0],[8,"href",4]],[[null,"click"]],function(l,n,u){var t=!0;return"click"===n&&(t=!1!==e.Xa(l,47).onClick(u.button,u.ctrlKey,u.metaKey,u.shiftKey)&&t),t},null,null)),e.Ma(47,671744,null,0,p.l,[p.k,p.a,g.h],{routerLink:[0,"routerLink"]},null),(l()(),e.Na(48,0,null,null,0,"i",[["class","fas fa-angle-right"]],null,null,null,null,null)),(l()(),e.Na(49,0,null,null,1,"div",[["class","image-product"]],null,null,null,null,null)),(l()(),e.Na(50,0,null,null,0,"img",[["alt",""],["src","assets/images/-e-face_dj.png"]],null,null,null,null,null)),(l()(),e.Na(51,0,null,null,14,"div",[["class","col-lg-3"]],null,null,null,null,null)),(l()(),e.Na(52,0,null,null,13,"div",[],[[8,"className",0]],[[null,"click"]],function(l,n,u){var e=!0;return"click"===n&&(e=!1!==l.component.classActive(4)&&e),e},null,null)),(l()(),e.Na(53,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA CARS"])),(l()(),e.Na(55,0,null,null,5,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Vehicle type/make/model"])),(l()(),e.Na(57,0,null,null,0,"br",[],null,null,null,null,null)),(l()(),e.cb(-1,null,[" recognition engine for intelligent"])),(l()(),e.Na(59,0,null,null,0,"br",[],null,null,null,null,null)),(l()(),e.cb(-1,null,[" transportation systems"])),(l()(),e.Na(61,0,null,null,2,"a",[["routerLink","luna-cars"]],[[1,"target",0],[8,"href",4]],[[null,"click"]],function(l,n,u){var t=!0;return"click"===n&&(t=!1!==e.Xa(l,62).onClick(u.button,u.ctrlKey,u.metaKey,u.shiftKey)&&t),t},null,null)),e.Ma(62,671744,null,0,p.l,[p.k,p.a,g.h],{routerLink:[0,"routerLink"]},null),(l()(),e.Na(63,0,null,null,0,"i",[["class","fas fa-angle-right"]],null,null,null,null,null)),(l()(),e.Na(64,0,null,null,1,"div",[["class","image-product"]],null,null,null,null,null)),(l()(),e.Na(65,0,null,null,0,"img",[["alt",""],["src","assets/images/-e-luna_cars.png"]],null,null,null,null,null))],function(l,n){l(n,17,0,"luna-sdk"),l(n,32,0,"luna-platform"),l(n,47,0,"face-dj"),l(n,62,0,"luna-cars")},function(l,n){var u=n.component;l(n,7,0,1==u.class?"active product":"product"),l(n,16,0,e.Xa(n,17).target,e.Xa(n,17).href),l(n,22,0,2==u.class?"active product":"product"),l(n,31,0,e.Xa(n,32).target,e.Xa(n,32).href),l(n,37,0,3==u.class?"active product":"product"),l(n,46,0,e.Xa(n,47).target,e.Xa(n,47).href),l(n,52,0,4==u.class?"active product":"product"),l(n,61,0,e.Xa(n,62).target,e.Xa(n,62).href)})}var b=e.Ja("app-products",c,function(l){return e.db(0,[(l()(),e.Na(0,0,null,null,1,"app-products",[],null,null,null,m,d)),e.Ma(1,114688,null,0,c,[],null,null)],function(l,n){l(n,1,0)},null)},{},{},[]),h=e.La({encapsulation:0,styles:[[".container[_ngcontent-%COMP%]{max-width:710px!important}.row[_ngcontent-%COMP%]{width:710px!important}.title[_ngcontent-%COMP%]{text-align:center;color:#545454;font-size:16px}.title[_ngcontent-%COMP%]   h5[_ngcontent-%COMP%]{font-family:MADE;color:#2782ff;font-size:10px;text-transform:uppercase;letter-spacing:1.39px;margin-top:84px}.title[_ngcontent-%COMP%]   h2[_ngcontent-%COMP%]{font-family:MADE;color:#2782ff;font-size:46px;text-transform:uppercase;letter-spacing:7.4px;margin-top:29px}.title[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{margin-top:75px;font-size:22px}.article[_ngcontent-%COMP%]   .line[_ngcontent-%COMP%]{height:4px;width:122px;background-color:#3182ff;margin:48px auto auto}.article[_ngcontent-%COMP%]   h3[_ngcontent-%COMP%]{font-size:25px;color:#2c75e6;letter-spacing:.36px;text-align:center;margin-top:65px;margin-bottom:45px}.article[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{font-size:16px;color:#545454;margin-bottom:45px}.article[_ngcontent-%COMP%]   h6[_ngcontent-%COMP%]{font-size:20px;color:#545454;margin-bottom:45px}.article[_ngcontent-%COMP%]   ul[_ngcontent-%COMP%]{padding-left:19px}.article[_ngcontent-%COMP%]   ul[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]{color:#2c75e6;padding-left:35px;padding-bottom:45px}.article[_ngcontent-%COMP%]   ul[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]   span[_ngcontent-%COMP%]{color:#545454;font-size:16px}.article[_ngcontent-%COMP%]   .check[_ngcontent-%COMP%]{width:50%;display:inline-block}.article[_ngcontent-%COMP%]   .info[_ngcontent-%COMP%]{border-left:4px solid #3182ff;padding:19px 0 19px 66px;margin-bottom:45px}.article[_ngcontent-%COMP%]   .info[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{color:#2c75e6;font-family:MADE;letter-spacing:.52px;font-size:26px;margin:0}.article[_ngcontent-%COMP%]   .note[_ngcontent-%COMP%]{background-color:#edf3fc;margin-bottom:45px}.article[_ngcontent-%COMP%]   .note[_ngcontent-%COMP%]   h5[_ngcontent-%COMP%]{font-family:MADE;color:#2c75e6;font-size:32px;text-align:center;margin-top:50px;letter-spacing:.64px;margin-bottom:0}.article[_ngcontent-%COMP%]   .note[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{text-align:center;font-size:22px;margin:64px}.article[_ngcontent-%COMP%]   .attention[_ngcontent-%COMP%]{background-color:#3182ff;margin-bottom:45px}.article[_ngcontent-%COMP%]   .attention[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{text-align:center;font-size:22px;margin:64px;color:#fff}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]{background-color:#edf3fc;padding:48px 61px;display:inline-block;width:926px;margin-left:-108px;margin-bottom:29px}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]{width:100%;display:inline-table;color:#545454;font-size:20px}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]   .tb-head[_ngcontent-%COMP%]{background-color:#fff;font-family:MADE;font-weight:500;box-shadow:0 20px 29px rgba(128,147,174,.15)}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]   .tb-head[_ngcontent-%COMP%]   th[_ngcontent-%COMP%]{text-align:center;border:none;font-weight:500;font-family:MADE}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]   .tb-head[_ngcontent-%COMP%]   th[_ngcontent-%COMP%]:first-child{border-top-left-radius:4px;border-bottom-left-radius:4px}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]   .tb-head[_ngcontent-%COMP%]   th[_ngcontent-%COMP%]:last-child{border-top-right-radius:4px;border-bottom-right-radius:4px}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]   tr[_ngcontent-%COMP%]   td[_ngcontent-%COMP%]{text-align:center;font-size:17px}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   h5[_ngcontent-%COMP%]{font-family:MADE;font-weight:500;font-size:20px;letter-spacing:.21px;color:#2782ff;margin-bottom:45px;text-align:center}.article[_ngcontent-%COMP%]   .image[_ngcontent-%COMP%]{min-width:926px;margin-left:-93px;margin-bottom:45px;text-align:center}.article[_ngcontent-%COMP%]   .image[_ngcontent-%COMP%]   h5[_ngcontent-%COMP%]{font-size:20px;letter-spacing:.4px;color:#2c75e6;font-family:MADE;margin-bottom:45px}.article[_ngcontent-%COMP%]   .image[_ngcontent-%COMP%]   img[_ngcontent-%COMP%]{margin-top:45px;margin-bottom:35px;width:100%}.article[_ngcontent-%COMP%]   .image[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{font-size:17px;margin-bottom:45px;width:570px;display:inline-block}.container-blue[_ngcontent-%COMP%]{background-color:#3182ff}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]{max-width:1280px;margin:auto;padding-top:78px}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   div[_ngcontent-%COMP%]{width:50%;display:inline-block;text-align:center;margin-top:60px}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   img[_ngcontent-%COMP%]{position:relative;bottom:45px}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   .img[_ngcontent-%COMP%]{display:block;margin:auto}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   .center[_ngcontent-%COMP%]{float:left;position:relative;bottom:80px}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   span[_ngcontent-%COMP%]{font-family:MADE;font-size:32px;font-weight:500;letter-spacing:.34px;color:#fff;display:inline-block}"]],data:{}});function f(l){return e.db(0,[(l()(),e.Na(0,0,null,null,182,"div",[["class","container"]],null,null,null,null,null)),(l()(),e.Na(1,0,null,null,9,"div",[["class","row title"]],null,null,null,null,null)),(l()(),e.Na(2,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(3,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Products"])),(l()(),e.Na(5,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(6,0,null,null,1,"h2",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face.dj"])),(l()(),e.Na(8,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(9,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["FaceDJ is an app that clones you into virtual reality. All that is needed is a photo of yourself."])),(l()(),e.Na(11,0,null,null,11,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(12,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(13,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(14,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Introduction"])),(l()(),e.Na(16,0,null,null,6,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(17,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["We implement and develop state of the art technologies for 3D face reconstruction. Our technologies are based on techniques from machine learning, computer vision and computational geometry."])),(l()(),e.Na(19,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["The accuracy of our algorithms is measured quantitatively and qualitatively. We use ground truth 3D data for quantitative evaluation and we also survey users to monitor their perception of our 3D faces."])),(l()(),e.Na(21,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["The structure of this document is following: Sec. 2 describes the functionality of FaceDJ. Sec. 3 describes our expertise in the technologies that FaceDJ is based on. Sec. 4 describes how the quality of FaceDJ models is measured and assured. It also provides comparisons with state of the art"])),(l()(),e.Na(23,0,null,null,31,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(24,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(25,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(26,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Functionality"])),(l()(),e.Na(28,0,null,null,4,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(29,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["3D Face Creation"])),(l()(),e.Na(31,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["We create textured 3D faces from portrait photos. One photo is required per model."])),(l()(),e.Na(33,0,null,null,3,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(34,0,null,null,0,"img",[["alt",""],["src","assets/images/4-layers.1.png"]],null,null,null,null,null)),(l()(),e.Na(35,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Figure 1: 3D face creation example"])),(l()(),e.Na(37,0,null,null,4,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(38,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Head Creation"])),(l()(),e.Na(40,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["We create full head models by extrapolating face geometry and texture. "])),(l()(),e.Na(42,0,null,null,3,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(43,0,null,null,0,"img",[["alt",""],["src","assets/images/4-layers.2.png"]],null,null,null,null,null)),(l()(),e.Na(44,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Figure 2: Head creation example"])),(l()(),e.Na(46,0,null,null,4,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(47,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face Animation"])),(l()(),e.Na(49,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["We animate 3D faces using a video stream supplied by a user as input. User\u2019s facial expressions and gaze direction are transfered onto the model. We create 3D faces with eyes and oral cavity modeled as separate objects for animation."])),(l()(),e.Na(51,0,null,null,3,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(52,0,null,null,0,"img",[["alt",""],["src","assets/images/4-layers.3.png"]],null,null,null,null,null)),(l()(),e.Na(53,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Figure 3: Animation example"])),(l()(),e.Na(55,0,null,null,70,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(56,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(57,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(58,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Expertise"])),(l()(),e.Na(60,0,null,null,6,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(61,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Morphable Model Fittin"])),(l()(),e.Na(63,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Morphable models are essential for many algorithms performing 3D face reconstruction [1\u20135]. These algorithms may be classi\ufb01ed into two types: optimization-based and regression-based. Optimization-based algorithms directly imply the use of a morphable model. Regression-based algorithms often use the results of morphable model \ufb01tting as training data [3\u20135]."])),(l()(),e.Na(65,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Morphable models allow to generate faces in 3D [6]. The faces are controlled by relatively few parameters that adjust their shapes and expressions. These faces may be rendered from varying views and under di\ufb00erent illumination conditions."])),(l()(),e.Na(67,0,null,null,3,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(68,0,null,null,0,"img",[["alt",""],["src","assets/images/4-layers.4.png"]],null,null,null,null,null)),(l()(),e.Na(69,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Figure 4: Example renders from a morphable model"])),(l()(),e.Na(71,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(72,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Morphable model \ufb01tting reverts the process of image rendering: it seeks to \ufb01nd a combination of parameters that will result in a rendered image resembling the target image as closely as possible."])),(l()(),e.Na(74,0,null,null,3,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(75,0,null,null,0,"img",[["alt",""],["src","assets/images/2-layers.5(5).png"]],null,null,null,null,null)),(l()(),e.Na(76,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Figure 5: Example of a \ufb01tted model"])),(l()(),e.Na(78,0,null,null,3,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(79,0,null,null,0,"img",[["alt",""],["src","assets/images/Layer_539.6.png"]],null,null,null,null,null)),(l()(),e.Na(80,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Figure 6: Example images and corresponding 3d models from our training set."])),(l()(),e.Na(82,0,null,null,26,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(83,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Neural Network Inference"])),(l()(),e.Na(85,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["We process a face database using morphable model \ufb01tting algorithm, thus acquiring reconstructed 3d models, and train a MobileNet-based [7] neural network to predict facial geometry. In our work [8]1 we report the results of a network trained on the 300W face database [9]. Fig. 6 shows some examples from the training set."])),(l()(),e.Na(87,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Non-rigid Mesh Editing"])),(l()(),e.Na(89,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Non-rigid mesh editing techniques allow to solve the following task:"])),(l()(),e.Na(91,0,null,null,9,"ul",[],null,null,null,null,null)),(l()(),e.Na(92,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(93,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Adjust a local part of a face"])),(l()(),e.Na(95,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(96,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Integrate the adjusted part plausibly into the original face"])),(l()(),e.Na(98,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(99,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Leave the remaining parts of the face as close to unchanged as possible."])),(l()(),e.Na(101,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["This task is crucial for salient face parts, especially the end of the nose. See Fig. 7 for an example."])),(l()(),e.Na(103,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["We use an adaptation of the technique known as Laplacian Surface Editing [10] in combination with computer vision techniques in order to improve the alignment and appearance of salient face parts."])),(l()(),e.Na(105,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face and Eyes Landmarks Detection"])),(l()(),e.Na(107,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["To animate an avatar in real time we use face and eyes landmarks. For landmarks detection we use extremely fast neural network models optimized for real-time inference on mobile devices. Inference time for all the networks equals 10 ms on Samsung S7 G930F. To better capture subtle details of face and eyes movement we have created large in-house training set with a variety of human emotions. Sample of this dataset could be seen at Fig. 8."])),(l()(),e.Na(109,0,null,null,3,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(110,0,null,null,0,"img",[["alt",""],["src","ssets/images/4-layers.7.png"]],null,null,null,null,null)),(l()(),e.Na(111,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Figure 7: Example of non-rigid mesh editing"])),(l()(),e.Na(113,0,null,null,3,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(114,0,null,null,0,"img",[["alt",""],["src","assets/images/Layer_542.8.png"]],null,null,null,null,null)),(l()(),e.Na(115,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Figure 8: Example of labelled images from in-house landmarks dataset"])),(l()(),e.Na(117,0,null,null,3,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(118,0,null,null,0,"img",[["alt",""],["src","assets/images/Layer_543.9.png"]],null,null,null,null,null)),(l()(),e.Na(119,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Figure 9: Comparison of methods on images from BU4DFE (higher is better)"])),(l()(),e.Na(121,0,null,null,4,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(122,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Head Pose and Gaze Estimatio"])),(l()(),e.Na(124,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Accurate head pose and gaze estimation is a hard problem mainly due to the dif\ufb01culties in obtaining large labelled training set with large variations in head pose and external conditions. At the moment we estimate head position and eye pupil position directly from predicted landmarks. This approach allows us to create robust estimators that work in a wide range of conditions under 10 ms budget on mobile device."])),(l()(),e.Na(126,0,null,null,26,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(127,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(128,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(129,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Quality Measures"])),(l()(),e.Na(131,0,null,null,12,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(132,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Quantitative Evaluation"])),(l()(),e.Na(134,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Quantitative evaluation of 3D reconstruction accuracy requires ground truth 3D scans. We use BU4DFE dataset [11] for our evaluations. The error measure is the normalized vertex-wise mesh distance between the reconstructed 3D model and the ground truth 3D scan (see [8] for details). We also compare the accuracies of our algorithms with a few recent works [4,5,12]."])),(l()(),e.Na(136,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Fig. 9 shows cumulative error distributions for a few algorithms on a selection of photos from BU4DFE. Two curves in Fig. 9 are obtained using our algorithms. \u2019Fitting\u2019 curve re\ufb02ects the accuracy of our implementation of morphable model \ufb01tting algorithm Sec. 3.1. \u2019MobileFace\u2019 corresponds to our neural network Sec. 3.2."])),(l()(),e.Na(138,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Table 1 presents a comparison of model size and running time for our and a few recent networks"])),(l()(),e.Na(140,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["User Study"])),(l()(),e.Na(142,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["We conduct user studies using a service similar to Amazon Mechanical Turk. Users see an original photo and two avatars constructed from the photo, they are asked to select the preferred one and give some comments Fig. 10."])),(l()(),e.Na(144,0,null,null,3,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(145,0,null,null,0,"img",[["alt",""],["src","assets/images/Layer_544.10.png"]],null,null,null,null,null)),(l()(),e.Na(146,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Figure 10: Example screen from a user survey"])),(l()(),e.Na(148,0,null,null,4,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(149,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["This helps us to monitor how our avatars are perceived by users. It also gives us an opportunity to compare our avatars with the competition."])),(l()(),e.Na(151,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Speci\ufb01cally, in one of the studies we compared our avatars with avatars produced by an analogous service. An average of 70% of users voted for our avatars. Other than giving the overall stronger likeness as the reason for their choice, the users also commented on the facial details being reconstructed better in our avatars."])),(l()(),e.Na(153,0,null,null,29,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(154,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(155,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(156,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["References"])),(l()(),e.Na(158,0,null,null,24,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(159,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["[1] Thies, J., Zollh\xa8ofer, M., Stamminger, M., Theobalt, C., Nie\xdfner, M.: Face2face: Real-time face capture and reenactment of rgb videos. In: Computer Vision and Pattern Recognition (CVPR). (2016)"])),(l()(),e.Na(161,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["[2] Garrido, P., Zollhoefer, M., Casas, D., Valgaerts, L., Varanasi, K., Perez, P., Theobalt, C.: Reconstruction of personalized 3D face rigs from monocular video. In: ACM Trans. Graph. (Presented at SIGGRAPH 2016). (2016)"])),(l()(),e.Na(163,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["[3] Zhu, X., Lei, Z., Liu, X., Shi, H., Li, S.Z.: Face alignment across large poses: A 3D solution. In: Computer Vision and Pattern Recognition (CVPR). (2016)"])),(l()(),e.Na(165,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["[4] Jackson, A., Bulat, A., Argyriou, V., Tzimiropoulos, G.: Large pose 3D face reconstruction from a single image via direct volumetric cnn regression. In: International Conference on Computer Vision (ICCV). (2017)"])),(l()(),e.Na(167,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["[5] Tran, A.T., Hassner, T., Iacopo, M., Paz, E., Nirkin, Y., Medioni, G.: Extreme 3D face reconstruction: Looking past occlusions. In: arxiv preprint. (2017)"])),(l()(),e.Na(169,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["[6] Blanz, V., Vetter, T.: A morphable model for the synthesis of 3D faces. In: SIGGRAPH Conference Proceedings. (1999)"])),(l()(),e.Na(171,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["[7] Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H.: Mobilenets: E\ufb03cient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861 (2017)"])),(l()(),e.Na(173,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["[8] Chinaev, N., Chigorin, A., Laptev, I.: Mobileface: 3D face reconstruction with e\ufb03cient cnn regression. In: ECCV Workshop on people capture (PeopleCap). (2018)"])),(l()(),e.Na(175,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["[9] Sagonas, C., Tzimiropoulos, G., Zafeiriou, S., Pantic, M.: 300 faces in-the-wild challenge: The \ufb01rst facial landmark localization challenge. In: International Conference on Computer Vision (ICCV). (2013)"])),(l()(),e.Na(177,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["[10] Sorkine, O., Cohen-Or, D., Lipman, Y., Alexa, M., R\xa8ossl, C., Seidel, H.P.: Laplacian surface editing. In: Proceedings of the 2004 Eurographics/ACM SIGGRAPH symposium on Geometry processing, ACM (2004) 175\u2013184"])),(l()(),e.Na(179,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["[11] Yin, L., Wei, X., Sun, Y., Wang, J., Rosato, M.: A 3D facial expression database for facial behavior research. In: Automatic Face and Gesture Recognition (FG). (2006)"])),(l()(),e.Na(181,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["[12] Tewari, A., Zollh\xa8ofer, M., Kim, H., Garrido, P., Bernard, F., Perez, P., Theobalt, C.: MoFA: Model-based Deep Convolutional Face Autoencoder for Unsupervised Monocular Reconstruction. In: International Conference on Computer Vision (ICCV). (2017)"])),(l()(),e.Na(183,0,null,null,10,"div",[["class","container-blue"]],null,null,null,null,null)),(l()(),e.Na(184,0,null,null,9,"div",[["class","container-width"]],null,null,null,null,null)),(l()(),e.Na(185,0,null,null,3,"div",[],null,null,null,null,null)),(l()(),e.Na(186,0,null,null,0,"img",[["alt",""],["class","img"],["src","assets/images/-e-apple_copy.png"]],null,null,null,null,null)),(l()(),e.Na(187,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Download on the App Store"])),(l()(),e.Na(189,0,null,null,4,"div",[],null,null,null,null,null)),(l()(),e.Na(190,0,null,null,0,"img",[["alt",""],["class","center"],["src","assets/images/-e-Rectangle_3459.png"]],null,null,null,null,null)),(l()(),e.Na(191,0,null,null,0,"img",[["alt",""],["class","img"],["src","assets/images/-e-face_dj_min.png"]],null,null,null,null,null)),(l()(),e.Na(192,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Try FACE.DJ Web Version"]))],null,null)}var N=e.Ja("app-face-dj",i,function(l){return e.db(0,[(l()(),e.Na(0,0,null,null,1,"app-face-dj",[],null,null,null,f,h)),e.Ma(1,114688,null,0,i,[],null,null)],function(l,n){l(n,1,0)},null)},{},{},[]),v=e.La({encapsulation:0,styles:[[""]],data:{}});function M(l){return e.db(0,[(l()(),e.Na(0,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,[" luna-cars works!\n"]))],null,null)}var P=e.Ja("app-luna-cars",o,function(l){return e.db(0,[(l()(),e.Na(0,0,null,null,1,"app-luna-cars",[],null,null,null,M,v)),e.Ma(1,114688,null,0,o,[],null,null)],function(l,n){l(n,1,0)},null)},{},{},[]),C=e.La({encapsulation:0,styles:[[".container[_ngcontent-%COMP%]{max-width:710px!important}.row[_ngcontent-%COMP%]{width:710px!important}.title[_ngcontent-%COMP%]{text-align:center;color:#545454;font-size:16px}.title[_ngcontent-%COMP%]   h5[_ngcontent-%COMP%]{font-family:MADE;color:#2782ff;font-size:10px;text-transform:uppercase;letter-spacing:1.39px;margin-top:84px}.title[_ngcontent-%COMP%]   h2[_ngcontent-%COMP%]{font-family:MADE;color:#2782ff;font-size:46px;text-transform:uppercase;letter-spacing:7.4px;margin-top:29px}.title[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{margin-top:75px;font-size:22px}.article[_ngcontent-%COMP%]   .line[_ngcontent-%COMP%]{height:4px;width:122px;background-color:#3182ff;margin:48px auto auto}.article[_ngcontent-%COMP%]   h3[_ngcontent-%COMP%]{font-size:25px;color:#2c75e6;letter-spacing:.36px;text-align:center;margin-top:65px;margin-bottom:45px}.article[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{font-size:16px;color:#545454;margin-bottom:45px}.article[_ngcontent-%COMP%]   h6[_ngcontent-%COMP%]{font-size:20px;color:#545454;margin-bottom:45px}.article[_ngcontent-%COMP%]   ul[_ngcontent-%COMP%]{padding-left:19px}.article[_ngcontent-%COMP%]   ul[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]{color:#2c75e6;padding-left:35px;padding-bottom:45px}.article[_ngcontent-%COMP%]   ul[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]   span[_ngcontent-%COMP%]{color:#545454;font-size:16px}.article[_ngcontent-%COMP%]   .check[_ngcontent-%COMP%]{width:50%;display:inline-block}.article[_ngcontent-%COMP%]   .info[_ngcontent-%COMP%]{border-left:4px solid #3182ff;padding:19px 0 19px 66px;margin-bottom:45px}.article[_ngcontent-%COMP%]   .info[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{color:#2c75e6;font-family:MADE;letter-spacing:.52px;font-size:26px;margin:0}.article[_ngcontent-%COMP%]   .note[_ngcontent-%COMP%]{background-color:#edf3fc;margin-bottom:45px}.article[_ngcontent-%COMP%]   .note[_ngcontent-%COMP%]   h5[_ngcontent-%COMP%]{font-family:MADE;color:#2c75e6;font-size:32px;text-align:center;margin-top:50px;letter-spacing:.64px;margin-bottom:0}.article[_ngcontent-%COMP%]   .note[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{text-align:center;font-size:22px;margin:64px}.article[_ngcontent-%COMP%]   .attention[_ngcontent-%COMP%]{background-color:#3182ff;margin-bottom:45px}.article[_ngcontent-%COMP%]   .attention[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{text-align:center;font-size:22px;margin:64px;color:#fff}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]{background-color:#edf3fc;padding:48px 61px;display:inline-block;width:926px;margin-left:-108px;margin-bottom:29px}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]{width:100%;display:inline-table;color:#545454;font-size:20px}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]   .tb-head[_ngcontent-%COMP%]{background-color:#fff;font-family:MADE;font-weight:500;box-shadow:0 20px 29px rgba(128,147,174,.15)}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]   .tb-head[_ngcontent-%COMP%]   th[_ngcontent-%COMP%]{text-align:center;border:none;font-weight:500;font-family:MADE}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]   .tb-head[_ngcontent-%COMP%]   th[_ngcontent-%COMP%]:first-child{border-top-left-radius:4px;border-bottom-left-radius:4px}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]   .tb-head[_ngcontent-%COMP%]   th[_ngcontent-%COMP%]:last-child{border-top-right-radius:4px;border-bottom-right-radius:4px}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]   tr[_ngcontent-%COMP%]   td[_ngcontent-%COMP%]{text-align:center;font-size:17px}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   h5[_ngcontent-%COMP%]{font-family:MADE;font-weight:500;font-size:20px;letter-spacing:.21px;color:#2782ff;margin-bottom:45px;text-align:center}.article[_ngcontent-%COMP%]   .image[_ngcontent-%COMP%]{background-color:#edf3fc;padding:0 41px;min-width:926px;margin-left:-93px;margin-bottom:45px;text-align:center}.article[_ngcontent-%COMP%]   .image[_ngcontent-%COMP%]   h5[_ngcontent-%COMP%]{font-size:24px;color:#545454;margin-top:45px}.article[_ngcontent-%COMP%]   .image[_ngcontent-%COMP%]   img[_ngcontent-%COMP%]{margin-top:45px;margin-bottom:35px}.article[_ngcontent-%COMP%]   .image[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{font-size:17px;margin-bottom:45px;width:570px;display:inline-block}.container-blue[_ngcontent-%COMP%]{background-color:#3182ff}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]{max-width:1280px;margin:auto;padding-top:78px}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   img[_ngcontent-%COMP%]{position:relative;bottom:45px}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   span[_ngcontent-%COMP%]{font-family:MADE;font-size:32px;font-weight:500;letter-spacing:.34px;color:#fff;width:700px;display:inline-block}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   .buttons[_ngcontent-%COMP%]{float:right;margin-top:51px}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   .second[_ngcontent-%COMP%]{width:230px;background:#3182ff;border:2px solid #fff;color:#fff;font-size:15px;padding:20px 0;cursor:pointer}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   .first[_ngcontent-%COMP%]{width:210px;background:#fff;border:2px solid #fff;color:#3182ff;font-size:15px;padding:20px 0;margin-right:12px;cursor:pointer}.container-image[_ngcontent-%COMP%]{background:url(Depositphotos_39039033_xl-2015_copy.9472116097a7fc71cdf6.png);-webkit-filter:brightness(.5)}.container-image[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]{max-width:1280px;margin:auto;padding-top:78px;padding-bottom:77px}.container-image[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   span[_ngcontent-%COMP%]{font-family:MADE;font-size:32px;font-weight:500;letter-spacing:.34px;color:#fff}.container-image[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   span[_ngcontent-%COMP%]:last-child{float:right;font-weight:400}"]],data:{}});function O(l){return e.db(0,[(l()(),e.Na(0,0,null,null,219,"div",[["class","container"]],null,null,null,null,null)),(l()(),e.Na(1,0,null,null,11,"div",[["class","row title"]],null,null,null,null,null)),(l()(),e.Na(2,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(3,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Products"])),(l()(),e.Na(5,0,null,null,4,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(6,0,null,null,3,"h2",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA"])),(l()(),e.Na(8,0,null,null,0,"br",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["PLATFORM"])),(l()(),e.Na(10,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(11,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA PLATFORM is a biometric data management system that offers great flexibility to create scenarios of varying complexity for integrated face recognition "])),(l()(),e.Na(13,0,null,null,64,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(14,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(15,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(16,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Overview"])),(l()(),e.Na(18,0,null,null,29,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(19,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA PLATFORM is a Web Service implementation of LUNA SDK designed to solve the following tasks: "])),(l()(),e.Na(21,0,null,null,12,"ul",[["class","check"]],null,null,null,null,null)),(l()(),e.Na(22,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(23,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face detection"])),(l()(),e.Na(25,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(26,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face descriptor extraction"])),(l()(),e.Na(28,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(29,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face descriptor storage and fast searching"])),(l()(),e.Na(31,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(32,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face descriptor logical grouping"])),(l()(),e.Na(34,0,null,null,9,"ul",[["class","check"]],null,null,null,null,null)),(l()(),e.Na(35,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(36,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face descriptor 1:1, 1:N and N:N matching"])),(l()(),e.Na(38,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(39,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face attributes estimation such as gender, age and emotions"])),(l()(),e.Na(41,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(42,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face matching events logging and notification generation"])),(l()(),e.Na(44,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Basic graphical user interface is provided for the described above features with system user account management and access restriction tools."])),(l()(),e.Na(46,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA PLATFORM consists of several components: API, CORE, Events and statistics, UI and Administration Services"])),(l()(),e.Na(48,0,null,null,1,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(49,0,null,null,0,"img",[["alt",""],["src","assets/images/50-layers.png"]],null,null,null,null,null)),(l()(),e.Na(50,0,null,null,4,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(51,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["The system is designed to receive still images or individual video frames as an input where it detects all human faces that meet user-defined set of parameters such as face size, face angle and quality index."])),(l()(),e.Na(53,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Each detected face may be converted into a special set of unique features called \u201cface descriptor\u201d. Face descriptor requires much less storage memory in comparison with a source face image. This conversion process is called descriptor extraction. All extracted face descriptors are automatically preserved in the system database."])),(l()(),e.Na(55,0,null,null,2,"div",[["class","col-lg-12 info"]],null,null,null,null,null)),(l()(),e.Na(56,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["It is impossible to restore original face image form the face descriptor, which is important for personal data protection regulation compliance "])),(l()(),e.Na(58,0,null,null,1,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(59,0,null,null,0,"img",[["alt",""],["src","assets/images/43-layers.1.png"]],null,null,null,null,null)),(l()(),e.Na(60,0,null,null,6,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(61,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Once a face descriptor is stored in the DB, LUNA PLATFORM does not need the source image any longer. However, it can be configured to keep portrait images for presentation and system upgrade purposes. LUNA PLATFORM provides a customizable storage facility with multiple backing options to choose from. "])),(l()(),e.Na(63,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face descriptors may be compared to determine whether they belong to the same person or not. This comparison process is called face descriptor matching."])),(l()(),e.Na(65,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA PLATFORM implements face verification (1:1 matching), face identification (1:N matching) and face clustering (N:N matching)."])),(l()(),e.Na(67,0,null,null,1,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(68,0,null,null,0,"img",[["alt",""],["src","assets/images/52-layers.2.png"]],null,null,null,null,null)),(l()(),e.Na(69,0,null,null,8,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(70,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA API service is the main gateway to the system. It provides a RESTful interface allowing the clients to use aforementioned detection, extraction and matching procedures. The API is performant and flexible and allows 3rd-party systems and smart device integration."])),(l()(),e.Na(72,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Events & Statistics service logs all requests for face descriptor extraction and matching. Each such request is referred to as an event. The service allows gathering various event statistics including duration, distribution in time, error to success ratio and other metrics. The service is also capable of event notification in real time via WebSockets. This enables easy integration with chat bots, web sites and other applications. "])),(l()(),e.Na(74,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["UI service implements graphical user interface. It builds atop of the same public API. "])),(l()(),e.Na(76,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Administration service solves common maintenance tasks including user account management (creation, suspension and removal), system monitoring and upgrades."])),(l()(),e.Na(78,0,null,null,40,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(79,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(80,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(81,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA API"])),(l()(),e.Na(83,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(84,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA API is designed to provide restricted user access to system resources such as face descriptors and their source face images (if you choose to store them) through a RESTful application interface."])),(l()(),e.Na(86,0,null,null,1,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(87,0,null,null,0,"img",[["alt",""],["src","assets/images/76-layers.3.png"]],null,null,null,null,null)),(l()(),e.Na(88,0,null,null,22,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(89,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Storage subsystem may be configured to preserve portrait images and other binary data. Various storage drivers are supported, including direct HDD storage and Amazon S3-compatible object storages. "])),(l()(),e.Na(91,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Storage and Accounts subsystem communicates with the CORE service to utilize its processing capabilities and access face descriptor storage."])),(l()(),e.Na(93,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA API implements multiple authorization methods: "])),(l()(),e.Na(95,0,null,null,6,"ul",[],null,null,null,null,null)),(l()(),e.Na(96,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(97,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Authorization using a login and password. This type is used for users and administrators\u2019 authorization to their accounts;"])),(l()(),e.Na(99,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(100,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Authorization using an API token. The tokens are used to authorize third-party systems (or devices) with limited user account rights. For example, when you need to receive videos from IP cameras, you should use tokens to authorize them."])),(l()(),e.Na(102,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA API implements several approaches to logical face descriptor grouping: "])),(l()(),e.Na(104,0,null,null,6,"ul",[],null,null,null,null,null)),(l()(),e.Na(105,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(106,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Grouping face descriptors belonging to the same real-world person together by using \u201cpersons\u201d feature of the system; "])),(l()(),e.Na(108,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(109,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Grouping \u201cpersons\u201d or individual descriptors using \u201clists\u201d feature of the system."])),(l()(),e.Na(111,0,null,null,4,"div",[["class","col-lg-12 note"]],null,null,null,null,null)),(l()(),e.Na(112,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Example:"])),(l()(),e.Na(114,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["You can create \u201cVIP Customers\u201d list, where each \u201cperson\u201d has one or several face descriptors. "])),(l()(),e.Na(116,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(117,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["It is possible to attach user-defined information to \u201clists\u201d and \u201cpersons\u201d even if the information is not used by the platform. The information may be useful upon integration of LUNA PLATFORM with 3rd-party systems."])),(l()(),e.Na(119,0,null,null,20,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(120,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(121,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(122,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA API"])),(l()(),e.Na(124,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(125,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA CORE service is a scalable system that solves all computation-intensive tasks like face detection, image normalization, face descriptor extraction and matching."])),(l()(),e.Na(127,0,null,null,1,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(128,0,null,null,0,"img",[["alt",""],["src","assets/images/53-layers.4.png"]],null,null,null,null,null)),(l()(),e.Na(129,0,null,null,10,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(130,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Computational tasks are performed by workers. Workers are dedicated processes that take tasks and produce results. Workers do not communicate with each other and are isolated and stateless. Workers obtain tasks via network and may be distributed across several servers. There may be unlimited number of workers, and new workers may be added dynamically, hence scaling is possible."])),(l()(),e.Na(132,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["There are two workers in LUNA CORE \u2013 Extractor and Matcher. "])),(l()(),e.Na(134,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA CORE service provides a communication channel for the API service, which dispatches API requests through a message service to deliver tasks to appropriate workers."])),(l()(),e.Na(136,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["A separate message queue service called MQ Broker is responsible for task dispatching to the workers and returning results. It is possible to use industry-proven messaging systems based on AMQP protocol, like RabbitMQ."])),(l()(),e.Na(138,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA CORE service analyzes incoming tasks before dispatching them to workers and can optimize some of them. For example, it may split large matching task into several smaller tasks processed concurrently to utilize multiple matching workers at once. "])),(l()(),e.Na(140,0,null,null,36,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(141,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(142,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(143,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA API"])),(l()(),e.Na(145,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(146,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Event & Statistics service allows keeping track of all requests that LUNA PLATFORM processes."])),(l()(),e.Na(148,0,null,null,1,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(149,0,null,null,0,"img",[["alt",""],["src","assets/images/26-layers.5.png"]],null,null,null,null,null)),(l()(),e.Na(150,0,null,null,21,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(151,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["It is possible to collect multiple metrics per request: "])),(l()(),e.Na(153,0,null,null,12,"ul",[],null,null,null,null,null)),(l()(),e.Na(154,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(155,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Time of the request execution (number of requests per second)"])),(l()(),e.Na(157,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(158,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Request status (succeeded, failed)"])),(l()(),e.Na(160,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(161,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Request status before failure"])),(l()(),e.Na(163,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(164,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Other metrics."])),(l()(),e.Na(166,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Event & Statistics service gathers statistics in a special in-memory DBMS (Influx DB) optimized for time series storage. This allows retrieving metrics for one or multiple counters for a given period very quickly. One may visualize and browse the collected data using third party software like Grafana. "])),(l()(),e.Na(168,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Aside from accumulating statistics, it is possible to collect events. Event happens when face descriptor is extracted or matched. It contains the same data as LUNA API returns in response to user request that triggers the event. "])),(l()(),e.Na(170,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Events are delivered in real-time by means of web sockets making it easy to implement a custom listener no matter should it run as a native application or as a script in a web browser. It is possible to subscribe to multiple events at once."])),(l()(),e.Na(172,0,null,null,4,"div",[["class","col-lg-12 note"]],null,null,null,null,null)),(l()(),e.Na(173,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Example:"])),(l()(),e.Na(175,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["You have a list of VIP guests. You can receive notifications to a smartphone about the guests\u2019 arrival using an ad hoc application that has subscription to the Event & Statistics service. "])),(l()(),e.Na(177,0,null,null,22,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(178,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(179,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(180,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["UI Service"])),(l()(),e.Na(182,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["UI service is a web application that implements a graphical interface for LUNA PLATFORM users. This interface supports all basic actions normally available through LUNA API, such as: "])),(l()(),e.Na(184,0,null,null,15,"ul",[],null,null,null,null,null)),(l()(),e.Na(185,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(186,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Registration and user log in"])),(l()(),e.Na(188,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(189,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Image uploading and portrait gallery browsing"])),(l()(),e.Na(191,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(192,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Persons and lists management"])),(l()(),e.Na(194,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(195,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Person identification, verification and generic descriptor matching tasks"])),(l()(),e.Na(197,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(198,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Token management."])),(l()(),e.Na(200,0,null,null,19,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(201,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(202,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(203,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Administration Service"])),(l()(),e.Na(205,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Administration Service is a control panel-style web application. It provides a graphical user interface for solving common administrative tasks, including: "])),(l()(),e.Na(207,0,null,null,12,"ul",[],null,null,null,null,null)),(l()(),e.Na(208,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(209,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Viewing user accounts and their data"])),(l()(),e.Na(211,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(212,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Performing face descriptor CNN model update"])),(l()(),e.Na(214,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(215,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Removing face descriptors not attached to persons or lists"])),(l()(),e.Na(217,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(218,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Viewing system metrics with Grafana (a 3rd-party tool)"])),(l()(),e.Na(220,0,null,null,9,"div",[["class","container-blue"]],null,null,null,null,null)),(l()(),e.Na(221,0,null,null,8,"div",[["class","container-width"]],null,null,null,null,null)),(l()(),e.Na(222,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["We will be happy to share our broad industry experience in implementing efficient Computer Vision solutions and show our Products in action "])),(l()(),e.Na(224,0,null,null,0,"img",[["alt",""],["src","assets/images/-e-Rectangle_3459.png"]],null,null,null,null,null)),(l()(),e.Na(225,0,null,null,4,"div",[["class","buttons"]],null,null,null,null,null)),(l()(),e.Na(226,0,null,null,1,"button",[["class","first"]],null,null,null,null,null)),(l()(),e.cb(-1,null,["Tell me more"])),(l()(),e.Na(228,0,null,null,1,"button",[["class","second"]],null,null,null,null,null)),(l()(),e.cb(-1,null,["Request free Demo"])),(l()(),e.Na(230,0,null,null,5,"div",[["class","container-image"]],null,null,null,null,null)),(l()(),e.Na(231,0,null,null,4,"div",[["class","container-width"]],null,null,null,null,null)),(l()(),e.Na(232,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Learn more about LUNA PLATFORM application scenarios"])),(l()(),e.Na(234,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.Na(235,0,null,null,0,"i",[["class","fas fa-angle-right"]],null,null,null,null,null))],null,null)}var x=e.Ja("app-luna-products",t,function(l){return e.db(0,[(l()(),e.Na(0,0,null,null,1,"app-luna-products",[],null,null,null,O,C)),e.Ma(1,114688,null,0,t,[],null,null)],function(l,n){l(n,1,0)},null)},{},{},[]),_=e.La({encapsulation:0,styles:[[".container[_ngcontent-%COMP%]{max-width:710px!important}.row[_ngcontent-%COMP%]{width:710px!important}.title[_ngcontent-%COMP%]{text-align:center;color:#545454;font-size:16px}.title[_ngcontent-%COMP%]   h5[_ngcontent-%COMP%]{font-family:MADE;color:#2782ff;font-size:10px;text-transform:uppercase;letter-spacing:1.39px;margin-top:84px}.title[_ngcontent-%COMP%]   h2[_ngcontent-%COMP%]{font-family:MADE;color:#2782ff;font-size:46px;text-transform:uppercase;letter-spacing:7.4px;margin-top:29px}.title[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{margin-top:75px;font-size:22px}.article[_ngcontent-%COMP%]   .line[_ngcontent-%COMP%]{height:4px;width:122px;background-color:#3182ff;margin:48px auto auto}.article[_ngcontent-%COMP%]   h3[_ngcontent-%COMP%]{font-size:25px;color:#2c75e6;letter-spacing:.36px;text-align:center;margin-top:65px;margin-bottom:45px}.article[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{font-size:16px;color:#545454;margin-bottom:45px}.article[_ngcontent-%COMP%]   h6[_ngcontent-%COMP%]{font-size:20px;color:#545454;margin-bottom:45px}.article[_ngcontent-%COMP%]   ul[_ngcontent-%COMP%]{padding-left:19px}.article[_ngcontent-%COMP%]   ul[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]{color:#2c75e6;padding-left:35px;padding-bottom:45px}.article[_ngcontent-%COMP%]   ul[_ngcontent-%COMP%]   li[_ngcontent-%COMP%]   span[_ngcontent-%COMP%]{color:#545454;font-size:16px}.article[_ngcontent-%COMP%]   .info[_ngcontent-%COMP%]{border-left:4px solid #3182ff;padding:19px 0 19px 66px;margin-bottom:45px}.article[_ngcontent-%COMP%]   .info[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{color:#2c75e6;font-family:MADE;letter-spacing:.52px;font-size:26px;margin:0}.article[_ngcontent-%COMP%]   .note[_ngcontent-%COMP%]{background-color:#edf3fc;margin-bottom:45px}.article[_ngcontent-%COMP%]   .note[_ngcontent-%COMP%]   h5[_ngcontent-%COMP%]{font-family:MADE;color:#2c75e6;font-size:32px;text-align:center;margin-top:50px;letter-spacing:.64px;margin-bottom:0}.article[_ngcontent-%COMP%]   .note[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{text-align:center;font-size:22px;margin:64px}.article[_ngcontent-%COMP%]   .attention[_ngcontent-%COMP%]{background-color:#3182ff;margin-bottom:45px}.article[_ngcontent-%COMP%]   .attention[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{text-align:center;font-size:22px;margin:64px;color:#fff}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]{background-color:#edf3fc;padding:48px 61px;display:inline-block;width:926px;margin-left:-108px;margin-bottom:29px}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]{width:100%;display:inline-table;color:#545454;font-size:20px}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]   .tb-head[_ngcontent-%COMP%]{background-color:#fff;font-family:MADE;font-weight:500;box-shadow:0 20px 29px rgba(128,147,174,.15)}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]   .tb-head[_ngcontent-%COMP%]   th[_ngcontent-%COMP%]{text-align:center;border:none;font-weight:500;font-family:MADE}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]   .tb-head[_ngcontent-%COMP%]   th[_ngcontent-%COMP%]:first-child{border-top-left-radius:4px;border-bottom-left-radius:4px}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]   .tb-head[_ngcontent-%COMP%]   th[_ngcontent-%COMP%]:last-child{border-top-right-radius:4px;border-bottom-right-radius:4px}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   table[_ngcontent-%COMP%]   tbody[_ngcontent-%COMP%]   tr[_ngcontent-%COMP%]   td[_ngcontent-%COMP%]{text-align:center;font-size:17px}.article[_ngcontent-%COMP%]   .table[_ngcontent-%COMP%]   h5[_ngcontent-%COMP%]{font-family:MADE;font-weight:500;font-size:20px;letter-spacing:.21px;color:#2782ff;margin-bottom:45px;text-align:center}.article[_ngcontent-%COMP%]   .image[_ngcontent-%COMP%]{background-color:#edf3fc;padding:0 41px;min-width:926px;margin-left:-93px;margin-bottom:45px;text-align:center}.article[_ngcontent-%COMP%]   .image[_ngcontent-%COMP%]   h5[_ngcontent-%COMP%]{font-size:24px;color:#545454;margin-top:45px}.article[_ngcontent-%COMP%]   .image[_ngcontent-%COMP%]   img[_ngcontent-%COMP%]{margin-top:45px;margin-bottom:35px}.article[_ngcontent-%COMP%]   .image[_ngcontent-%COMP%]   p[_ngcontent-%COMP%]{font-size:17px;margin-bottom:45px;width:570px;display:inline-block}.container-blue[_ngcontent-%COMP%]{background-color:#3182ff}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]{max-width:1280px;margin:auto;padding-top:78px}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   img[_ngcontent-%COMP%]{position:relative;bottom:45px}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   span[_ngcontent-%COMP%]{font-family:MADE;font-size:32px;font-weight:500;letter-spacing:.34px;color:#fff;width:700px;display:inline-block}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   .buttons[_ngcontent-%COMP%]{float:right;margin-top:51px}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   .second[_ngcontent-%COMP%]{width:230px;background:#3182ff;border:2px solid #fff;color:#fff;font-size:15px;padding:20px 0;cursor:pointer}.container-blue[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   .first[_ngcontent-%COMP%]{width:210px;background:#fff;border:2px solid #fff;color:#3182ff;font-size:15px;padding:20px 0;margin-right:12px;cursor:pointer}.container-image[_ngcontent-%COMP%]{background:url(Depositphotos_39039033_xl-2015_copy.9472116097a7fc71cdf6.png);-webkit-filter:brightness(.5)}.container-image[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]{max-width:1280px;margin:auto;padding-top:78px;padding-bottom:77px}.container-image[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   span[_ngcontent-%COMP%]{font-family:MADE;font-size:32px;font-weight:500;letter-spacing:.34px;color:#fff}.container-image[_ngcontent-%COMP%]   .container-width[_ngcontent-%COMP%]   span[_ngcontent-%COMP%]:last-child{float:right;font-weight:400}"]],data:{}});function y(l){return e.db(0,[(l()(),e.Na(0,0,null,null,606,"div",[["class","container"]],null,null,null,null,null)),(l()(),e.Na(1,0,null,null,15,"div",[["class","row title"]],null,null,null,null,null)),(l()(),e.Na(2,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(3,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Products"])),(l()(),e.Na(5,0,null,null,4,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(6,0,null,null,3,"h2",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA"])),(l()(),e.Na(8,0,null,null,0,"br",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["SDK"])),(l()(),e.Na(10,0,null,null,6,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(11,0,null,null,5,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA SDK is a pure face recognition engine that enables efficient"])),(l()(),e.Na(13,0,null,null,0,"br",[],null,null,null,null,null)),(l()(),e.cb(-1,null,[" and accurate processing of faces in images and live video stream and"])),(l()(),e.Na(15,0,null,null,0,"br",[],null,null,null,null,null)),(l()(),e.cb(-1,null,[" can run on a wide range of devices "])),(l()(),e.Na(17,0,null,null,43,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(18,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(19,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(20,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Overview"])),(l()(),e.Na(22,0,null,null,35,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(23,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA SDK supports multiple platforms and comes in two editions: frontend edition and complete edition. "])),(l()(),e.Na(25,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Frontend edition"])),(l()(),e.Na(27,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Frontend edition is intended for lightweight solutions that do not need to implement face descriptor extraction and matching functions. "])),(l()(),e.Na(29,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Complete edition"])),(l()(),e.Na(31,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Complete edition contains all the features of the frontend edition but adds face descriptor extraction and matching functions. "])),(l()(),e.Na(33,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Supported software and hardware platforms differ depending on the editions described above."])),(l()(),e.Na(35,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA SDK is subdivided into several facilities. Each facility is dedicated to a single function. "])),(l()(),e.Na(37,0,null,null,20,"ul",[],null,null,null,null,null)),(l()(),e.Na(38,0,null,null,4,"li",[],null,null,null,null,null)),(l()(),e.Na(39,0,null,null,3,"span",[],null,null,null,null,null)),(l()(),e.Na(40,0,null,null,1,"strong",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Core facility stores shared low-level LUNA SDK types and factories."])),(l()(),e.cb(-1,null,[" Each facility is a set of classes dedicated to common problem domain."])),(l()(),e.Na(43,0,null,null,4,"li",[],null,null,null,null,null)),(l()(),e.Na(44,0,null,null,3,"span",[],null,null,null,null,null)),(l()(),e.Na(45,0,null,null,1,"strong",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face detection facility is dedicated to face detection."])),(l()(),e.cb(-1,null,[" It contains various face detector implementations and factories"])),(l()(),e.Na(48,0,null,null,4,"li",[],null,null,null,null,null)),(l()(),e.Na(49,0,null,null,3,"span",[],null,null,null,null,null)),(l()(),e.Na(50,0,null,null,1,"strong",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Attribute estimation facility"])),(l()(),e.cb(-1,null,[" is dedicated to various attributes estimation of both images (such as: blurriness, exposure, transformation, etc.) and depicted faces (such as: age, gender, emotions, etc.)"])),(l()(),e.Na(53,0,null,null,4,"li",[],null,null,null,null,null)),(l()(),e.Na(54,0,null,null,3,"span",[],null,null,null,null,null)),(l()(),e.Na(55,0,null,null,1,"strong",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Descriptor processing facility"])),(l()(),e.cb(-1,null,[" is dedicated to face descriptor extraction and matching. This facility contains various face descriptor extractors and containers as well as factories, required to produce them."])),(l()(),e.Na(58,0,null,null,2,"div",[["class","col-lg-12 info"]],null,null,null,null,null)),(l()(),e.Na(59,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face descriptor is a set of features, describing the face, invariant to face transformation, size or other parameters. Face descriptor matching allows judging with certain probability whether two face images received belong to the same person."])),(l()(),e.Na(61,0,null,null,29,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(62,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(63,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(64,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face Detection Facility"])),(l()(),e.Na(66,0,null,null,4,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(67,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face detection facility is responsible for quick and coarse detection tasks, like finding a face in an image."])),(l()(),e.Na(69,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Detection structure represents an images-space bounding rectangle of the detected object as well as the detection score which is a measure of confidence in the particular face classification result and may be used to pick one face of many with the higher \u201cconfidence\u201d score."])),(l()(),e.Na(71,0,null,null,4,"div",[["class","col-lg-12 note"]],null,null,null,null,null)),(l()(),e.Na(72,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Note:"])),(l()(),e.Na(74,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Detection score is the measure of classification confidence and not the source image quality. While the score is related to quality (low-quality data generally results in a lower score), it is not a valid metric to estimate the visual quality of an image. Special estimators exist to fulfill this task."])),(l()(),e.Na(76,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(77,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face alignment is the process of special key points (called \u201clandmarks\u201d) detection on a face. LUNA SDK performs landmark detection at the same time as the face detection since some of the landmarks are byproducts of that detection."])),(l()(),e.Na(79,0,null,null,2,"div",[["class","col-lg-12 attention"]],null,null,null,null,null)),(l()(),e.Na(80,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face landmarks or key points are not used for face recognition process in VisionLabs face recognition engine. They are required at the preprocessing stage of an incoming face image for getting the best possible shot of the face"])),(l()(),e.Na(82,0,null,null,8,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(83,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["At the very minimum, just 5 landmarks are required: two for eyes, one for a nose tip and two for mouth corners. Using these coordinates, one may warp the source face image for its further use with all other LUNA SDK embedded algorithms."])),(l()(),e.Na(85,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["More advanced 68-points face alignment method is also implemented and is a part of LUNA SDK."])),(l()(),e.Na(87,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Typical use case for 5 landmarks is face image warping for further utilization by other VisionLabs algorithms - quality and attribute estimators, descriptor extractors."])),(l()(),e.Na(89,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Typical use cases for 68 landmarks are segmentation and head pose estimation."])),(l()(),e.Na(91,0,null,null,285,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(92,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(93,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(94,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Attribute Estimation Facility"])),(l()(),e.Na(96,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(97,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Estimation facility is the only multi-purpose facility in LUNA SDK. It is designed as a collection of tools that help estimate various image or depicted object properties. These properties may be used to increase the precision of algorithms implemented by other LUNA SDK facilities or resolve custom business tasks."])),(l()(),e.Na(99,0,null,null,67,"div",[["class","col-lg-12 table"]],null,null,null,null,null)),(l()(),e.Na(100,0,null,null,64,"table",[],null,null,null,null,null)),(l()(),e.Na(101,0,null,null,63,"tbody",[],null,null,null,null,null)),(l()(),e.Na(102,0,null,null,8,"tr",[["class","tb-head"]],null,null,null,null,null)),(l()(),e.Na(103,0,null,null,1,"th",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Age (years)"])),(l()(),e.Na(105,0,null,null,1,"th",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Averege error (years)"])),(l()(),e.Na(107,0,null,null,1,"th",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Age (years)"])),(l()(),e.Na(109,0,null,null,1,"th",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Averege error (years)"])),(l()(),e.Na(111,0,null,null,8,"tr",[],null,null,null,null,null)),(l()(),e.Na(112,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["17-20"])),(l()(),e.Na(114,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb13.5"])),(l()(),e.Na(116,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["50-55"])),(l()(),e.Na(118,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb12.62"])),(l()(),e.Na(120,0,null,null,8,"tr",[],null,null,null,null,null)),(l()(),e.Na(121,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["20-25"])),(l()(),e.Na(123,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb11.68"])),(l()(),e.Na(125,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["55-60"])),(l()(),e.Na(127,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb12.51"])),(l()(),e.Na(129,0,null,null,8,"tr",[],null,null,null,null,null)),(l()(),e.Na(130,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["25-30"])),(l()(),e.Na(132,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb11.63"])),(l()(),e.Na(134,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["60-65"])),(l()(),e.Na(136,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb13.01"])),(l()(),e.Na(138,0,null,null,8,"tr",[],null,null,null,null,null)),(l()(),e.Na(139,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["30-35"])),(l()(),e.Na(141,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb12.21"])),(l()(),e.Na(143,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["65-70"])),(l()(),e.Na(145,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb14.08"])),(l()(),e.Na(147,0,null,null,8,"tr",[],null,null,null,null,null)),(l()(),e.Na(148,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["35-40"])),(l()(),e.Na(150,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb12.44"])),(l()(),e.Na(152,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["70-75"])),(l()(),e.Na(154,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb13.97"])),(l()(),e.Na(156,0,null,null,8,"tr",[],null,null,null,null,null)),(l()(),e.Na(157,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["40-45"])),(l()(),e.Na(159,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb12.60"])),(l()(),e.Na(161,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["75-80"])),(l()(),e.Na(163,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb14.43"])),(l()(),e.Na(165,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Age estimation precision"])),(l()(),e.Na(167,0,null,null,37,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(168,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face image quality estimator predicts visual quality of an image. The estimator is optimized for facial images processing and detects the following defects:"])),(l()(),e.Na(170,0,null,null,12,"ul",[],null,null,null,null,null)),(l()(),e.Na(171,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(172,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["face image is blurred"])),(l()(),e.Na(174,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(175,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["face image is underexposed (i.e., too dark)"])),(l()(),e.Na(177,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(178,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["face image is overexposed (i.e., too light)"])),(l()(),e.Na(180,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(181,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["face image color variation is low (i.e., image is monochrome or close to monochrome)"])),(l()(),e.Na(183,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Eye estimator aims to determine:"])),(l()(),e.Na(185,0,null,null,6,"ul",[],null,null,null,null,null)),(l()(),e.Na(186,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(187,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["eye state: open, closed or occluded"])),(l()(),e.Na(189,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(190,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["precise eye iris location and eyelid shape as an array of landmarks"])),(l()(),e.Na(192,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Poor quality images or ones that depict occluded eyes (think eyewear, hair, gestures) fall into the \u201cOccluded\u201d category."])),(l()(),e.Na(194,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Head pose estimator is designed to determine camera-space head pose. Since 3D head translation is hard to determine reliably without camera- specific calibration, only 3D rotation component is estimated."])),(l()(),e.Na(196,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["There are two head pose estimation methods available:"])),(l()(),e.Na(198,0,null,null,6,"ul",[],null,null,null,null,null)),(l()(),e.Na(199,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(200,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["estimate with 68 face-aligned landmarks"])),(l()(),e.Na(202,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(203,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["estimate with an input image in RGB format"])),(l()(),e.Na(205,0,null,null,39,"div",[["class","col-lg-12 table"]],null,null,null,null,null)),(l()(),e.Na(206,0,null,null,36,"table",[],null,null,null,null,null)),(l()(),e.Na(207,0,null,null,35,"tbody",[],null,null,null,null,null)),(l()(),e.Na(208,0,null,null,7,"tr",[["class","tb-head"]],null,null,null,null,null)),(l()(),e.Na(209,0,null,null,0,"th",[],null,null,null,null,null)),(l()(),e.Na(210,0,null,null,1,"th",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Range"])),(l()(),e.Na(212,0,null,null,1,"th",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["-45\xb0...+45\xb0"])),(l()(),e.Na(214,0,null,null,1,"th",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["<-45\xb0 or >+45\xb0"])),(l()(),e.Na(216,0,null,null,8,"tr",[],null,null,null,null,null)),(l()(),e.Na(217,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Average prediction error (per axis)"])),(l()(),e.Na(219,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Yaw"])),(l()(),e.Na(221,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb12.7\xb0"])),(l()(),e.Na(223,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb14.6\xb0"])),(l()(),e.Na(225,0,null,null,8,"tr",[],null,null,null,null,null)),(l()(),e.Na(226,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Average prediction error (per axis)"])),(l()(),e.Na(228,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Pitch"])),(l()(),e.Na(230,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb13.0\xb0"])),(l()(),e.Na(232,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb14.8\xb0"])),(l()(),e.Na(234,0,null,null,8,"tr",[],null,null,null,null,null)),(l()(),e.Na(235,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Average prediction error (per axis)"])),(l()(),e.Na(237,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Roll"])),(l()(),e.Na(239,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb13.0\xb0"])),(l()(),e.Na(241,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb14.6\xb0"])),(l()(),e.Na(243,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Head pose prediction precision"])),(l()(),e.Na(245,0,null,null,3,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(246,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA SDK implies the following coordinate system convention:"])),(l()(),e.Na(248,0,null,null,0,"img",[["alt",""],["src","assets/images/2-layers.1.png"]],null,null,null,null,null)),(l()(),e.Na(249,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(250,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Gaze estimator is designed to determine gaze direction relatively to head pose estimation."])),(l()(),e.Na(252,0,null,null,28,"div",[["class","col-lg-12 table"]],null,null,null,null,null)),(l()(),e.Na(253,0,null,null,27,"table",[],null,null,null,null,null)),(l()(),e.Na(254,0,null,null,26,"tbody",[],null,null,null,null,null)),(l()(),e.Na(255,0,null,null,7,"tr",[["class","tb-head"]],null,null,null,null,null)),(l()(),e.Na(256,0,null,null,0,"th",[],null,null,null,null,null)),(l()(),e.Na(257,0,null,null,1,"th",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Range"])),(l()(),e.Na(259,0,null,null,1,"th",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["-25\xb0...+25\xb0"])),(l()(),e.Na(261,0,null,null,1,"th",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["-25\xb0...-45\xb0 or >+25\xb0...+45\xb0"])),(l()(),e.Na(263,0,null,null,8,"tr",[],null,null,null,null,null)),(l()(),e.Na(264,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Average prediction error (per axis)"])),(l()(),e.Na(266,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Yaw"])),(l()(),e.Na(268,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb12.7\xb0"])),(l()(),e.Na(270,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb14.6\xb0"])),(l()(),e.Na(272,0,null,null,8,"tr",[],null,null,null,null,null)),(l()(),e.Na(273,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Average prediction error (per axis)"])),(l()(),e.Na(275,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Pitch"])),(l()(),e.Na(277,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb13.0\xb0"])),(l()(),e.Na(279,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["\xb14.8\xb0"])),(l()(),e.Na(281,0,null,null,55,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(282,0,null,null,3,"p",[],null,null,null,null,null)),(l()(),e.Na(283,0,null,null,1,"strong",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Smile estimator"])),(l()(),e.cb(-1,null,[" predicts smile and mouth occlusion."])),(l()(),e.Na(286,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Emotions estimator determines whether a facial expression corresponds to a broad interpretation of the display of certain emotions:"])),(l()(),e.Na(288,0,null,null,21,"ul",[],null,null,null,null,null)),(l()(),e.Na(289,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(290,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Anger"])),(l()(),e.Na(292,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(293,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Disgust"])),(l()(),e.Na(295,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(296,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Fear"])),(l()(),e.Na(298,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(299,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Happiness"])),(l()(),e.Na(301,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(302,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Surprise"])),(l()(),e.Na(304,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(305,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Sadness"])),(l()(),e.Na(307,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(308,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Neutral"])),(l()(),e.Na(310,0,null,null,3,"p",[],null,null,null,null,null)),(l()(),e.Na(311,0,null,null,1,"strong",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Ethnicity estimator"])),(l()(),e.cb(-1,null,[" aims to determine a person\u2019s ethnic group and/or race."])),(l()(),e.Na(314,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["There are 4 types of ethnic groups and races the estimator is currently able to distinguish:"])),(l()(),e.Na(316,0,null,null,12,"ul",[],null,null,null,null,null)),(l()(),e.Na(317,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(318,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Indian"])),(l()(),e.Na(320,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(321,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Asian"])),(l()(),e.Na(323,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(324,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Black"])),(l()(),e.Na(326,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(327,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["White"])),(l()(),e.Na(329,0,null,null,3,"p",[],null,null,null,null,null)),(l()(),e.Na(330,0,null,null,1,"strong",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Approximate garbage score estimator (AGS)"])),(l()(),e.cb(-1,null,[" determines the suitability of an image for later face descriptor extraction and matching."])),(l()(),e.Na(333,0,null,null,3,"p",[],null,null,null,null,null)),(l()(),e.Na(334,0,null,null,1,"strong",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Glasses estimator"])),(l()(),e.cb(-1,null,[" predicts eyewear on an image. The estimator outputs probability of prescription and sunglasses."])),(l()(),e.Na(337,0,null,null,30,"div",[["class","col-lg-12 table"]],null,null,null,null,null)),(l()(),e.Na(338,0,null,null,29,"table",[],null,null,null,null,null)),(l()(),e.Na(339,0,null,null,28,"tbody",[],null,null,null,null,null)),(l()(),e.Na(340,0,null,null,6,"tr",[["class","tb-head"]],null,null,null,null,null)),(l()(),e.Na(341,0,null,null,1,"th",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["State"])),(l()(),e.Na(343,0,null,null,1,"th",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["TPR"])),(l()(),e.Na(345,0,null,null,1,"th",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["FPR"])),(l()(),e.Na(347,0,null,null,6,"tr",[],null,null,null,null,null)),(l()(),e.Na(348,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["NoGlasses"])),(l()(),e.Na(350,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["0.997"])),(l()(),e.Na(352,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["0.00234"])),(l()(),e.Na(354,0,null,null,6,"tr",[],null,null,null,null,null)),(l()(),e.Na(355,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["EyeGlasses"])),(l()(),e.Na(357,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["0.9768"])),(l()(),e.Na(359,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["0.000783"])),(l()(),e.Na(361,0,null,null,6,"tr",[],null,null,null,null,null)),(l()(),e.Na(362,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["SunGlasses"])),(l()(),e.Na(364,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["0.9712"])),(l()(),e.Na(366,0,null,null,1,"td",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["0.000383"])),(l()(),e.Na(368,0,null,null,8,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(369,0,null,null,3,"p",[],null,null,null,null,null)),(l()(),e.Na(370,0,null,null,1,"strong",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Occlusion estimator"])),(l()(),e.cb(-1,null,[" determines whether the face is occluded by an object."])),(l()(),e.Na(373,0,null,null,3,"p",[],null,null,null,null,null)),(l()(),e.Na(374,0,null,null,1,"strong",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Child estimator"])),(l()(),e.cb(-1,null,[" determines whether the person is a child or not. We define \u201cchild\u201d as a person who is younger than 18."])),(l()(),e.Na(377,0,null,null,19,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(378,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(379,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(380,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Image Warping"])),(l()(),e.Na(382,0,null,null,14,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(383,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Warping is the process of face image normalization."])),(l()(),e.Na(385,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["The purpose of the process is to:"])),(l()(),e.Na(387,0,null,null,9,"ul",[],null,null,null,null,null)),(l()(),e.Na(388,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(389,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["compensate image plane rotation (roll angle)"])),(l()(),e.Na(391,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(392,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["center the image using eye positions"])),(l()(),e.Na(394,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(395,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["properly crop the image"])),(l()(),e.Na(397,0,null,null,42,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(398,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(399,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(400,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Descriptor Processing Facility"])),(l()(),e.Na(402,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(403,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face descriptor stores a compact vector of packed properties as well as some helper parameters that were used to extract these properties from the source face image. Together these parameters determine descriptor compatibility."])),(l()(),e.Na(405,0,null,null,4,"div",[["class","col-lg-12 note"]],null,null,null,null,null)),(l()(),e.Na(406,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Hint:"])),(l()(),e.Na(408,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Not all descriptors are compatible with each other. It is impossible to batch and match incompatible descriptors."])),(l()(),e.Na(410,0,null,null,8,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(411,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["We refer to all face descriptor comparison operations as face matching. The result of matching of two face descriptors is a distance between components of the corresponding parameter vectors. Thus, from a magnitude of this distance, we can judge with certain probability if two facial images depict the same real person. We call that probability a similarity score."])),(l()(),e.Na(413,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Face descriptors in LUNA SDK have backend and mobile implementations. Backend versions offer higher accuracy while mobile are faster and have smaller model files."])),(l()(),e.Na(415,0,null,null,3,"p",[],null,null,null,null,null)),(l()(),e.Na(416,0,null,null,1,"strong",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Descriptor extractor"])),(l()(),e.cb(-1,null,[" is the entity responsible for descriptor extraction."])),(l()(),e.Na(419,0,null,null,4,"div",[["class","col-lg-12 note"]],null,null,null,null,null)),(l()(),e.Na(420,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Hint:"])),(l()(),e.Na(422,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Descriptor extraction is one of the most computation-heavy operations of LUNA SDK. For this reason, threading must be considered."])),(l()(),e.Na(424,0,null,null,10,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(425,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Descriptor extraction implementation supports execution on GPUs."])),(l()(),e.Na(427,0,null,null,3,"p",[],null,null,null,null,null)),(l()(),e.Na(428,0,null,null,1,"strong",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Descriptor matching"])),(l()(),e.cb(-1,null,[" is an operation when a pair (or more) previously extracted descriptors are compared to find their similarity score. With this information, it is possible to implement face search and other analytic applications. "])),(l()(),e.Na(431,0,null,null,3,"p",[],null,null,null,null,null)),(l()(),e.Na(432,0,null,null,1,"strong",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Descriptor indexing"])),(l()(),e.cb(-1,null,[" helps accelerate face descriptor matching process by using a special index for face descriptor batch"])),(l()(),e.Na(435,0,null,null,4,"div",[["class","col-lg-12 note"]],null,null,null,null,null)),(l()(),e.Na(436,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Note:"])),(l()(),e.Na(438,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Descriptor index has no support of embedded and 32-bit desktop platforms."])),(l()(),e.Na(440,0,null,null,134,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(441,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(442,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(443,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Liveness Engine"])),(l()(),e.Na(445,0,null,null,6,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(446,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Liveness Engine is a wrapper library with added functionality, which utilizes LUNA SDK building blocks to produce different solutions for liveness detection problem. You can combine multiple liveness checks but keep in mind that excessive checks result in poor user experience."])),(l()(),e.Na(448,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Liveness engine is responsible for determining whether or not a living person\u2019s face is in a still image or in an image sequence. By \u201cimage sequence\u201d here we mean consequent frames of a video stream from a camera or a video file."])),(l()(),e.Na(450,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Liveness types are implemented according to the inheritance architecture:"])),(l()(),e.Na(452,0,null,null,1,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(453,0,null,null,0,"img",[["alt",""],["src","assets/images/25-layers.png"]],null,null,null,null,null)),(l()(),e.Na(454,0,null,null,33,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(455,0,null,null,2,"h6",[],null,null,null,null,null)),(l()(),e.Na(456,0,null,null,1,"strong",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Basic liveness check"])),(l()(),e.Na(458,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Basic liveness check types require single video sequence for operation. "])),(l()(),e.Na(460,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Each liveness type is inherited from the basic liveness class which utilizes a generic execution cycle and performs such common tasks as:"])),(l()(),e.Na(462,0,null,null,19,"ul",[],null,null,null,null,null)),(l()(),e.Na(463,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(464,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["basic initialization"])),(l()(),e.Na(466,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(467,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["face detection"])),(l()(),e.Na(469,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(470,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["additional data extraction / calculation"])),(l()(),e.Na(472,0,null,null,6,"li",[],null,null,null,null,null)),(l()(),e.Na(473,0,null,null,5,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["face tracking analysis"])),(l()(),e.Na(475,0,null,null,0,"br",[],null,null,null,null,null)),(l()(),e.cb(-1,null,[" -using detection rectangles"])),(l()(),e.Na(477,0,null,null,0,"br",[],null,null,null,null,null)),(l()(),e.cb(-1,null,[" -using landmark points"])),(l()(),e.Na(479,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(480,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["state change monitoring"])),(l()(),e.Na(482,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Each liveness test traces and analyzes primary estimated attribute chosen for liveness check and produces results. The result is positive if a user succeeds in the correct alteration of the attribute. Otherwise, the result is negative."])),(l()(),e.Na(484,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Angle liveness check"])),(l()(),e.Na(486,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Angle liveness additionally performs head pose estimation. Below are some of the examples of application of angle liveness."])),(l()(),e.Na(488,0,null,null,8,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(489,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Pitch angle"])),(l()(),e.Na(491,0,null,null,0,"img",[["alt",""],["src","assets/images/2-layers.2.png"]],null,null,null,null,null)),(l()(),e.Na(492,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["a. nod scenario means smooth head tilt in a positive direction until the set threshold is exceeded."])),(l()(),e.Na(494,0,null,null,0,"img",[["alt",""],["src","assets/images/2-layers.3.png"]],null,null,null,null,null)),(l()(),e.Na(495,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["b. head raise scenario requires smooth head tilt in a negative direction until the set threshold is exceeded."])),(l()(),e.Na(497,0,null,null,8,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(498,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Yaw angle"])),(l()(),e.Na(500,0,null,null,0,"img",[["alt",""],["src","assets/images/2-layers.4.png"]],null,null,null,null,null)),(l()(),e.Na(501,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["a. left turn scenario requires smooth head rotation in a positive direction until the set threshold is exceeded."])),(l()(),e.Na(503,0,null,null,0,"img",[["alt",""],["src","assets/images/2-layers.5.png"]],null,null,null,null,null)),(l()(),e.Na(504,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["d. right turn scenario requires smooth head rotation in a negative direction until the set threshold is exceeded."])),(l()(),e.Na(506,0,null,null,5,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(507,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Mouth liveness check"])),(l()(),e.Na(509,0,null,null,0,"img",[["alt",""],["src","assets/images/2-layers.6.png"]],null,null,null,null,null)),(l()(),e.Na(510,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Mouth liveness performs mouth landmarks analysis. In this scenario distance between mouth landmarks increases until the set threshold is exceeded (i.e., a user opens a mouth)."])),(l()(),e.Na(512,0,null,null,5,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(513,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Eyes liveness check"])),(l()(),e.Na(515,0,null,null,0,"img",[["alt",""],["src","assets/images/2-layers.7.png"]],null,null,null,null,null)),(l()(),e.Na(516,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Eye liveness performs eye state estimation and analysis. In this scenario a user should blink, i.e., both eyes are opened, closed and opened again simultaneously."])),(l()(),e.Na(518,0,null,null,5,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(519,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Eyebrows liveness check"])),(l()(),e.Na(521,0,null,null,0,"img",[["alt",""],["src","assets/images/2-layers.8.png"]],null,null,null,null,null)),(l()(),e.Na(522,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Eyebrow liveness performs eyebrow landmarks analysis. This scenario requires increase of the distance between eyebrows and eyes landmarks (i.e., eyebrow rising) until the set threshold is exceeded."])),(l()(),e.Na(524,0,null,null,5,"div",[["class","col-lg-12 image"]],null,null,null,null,null)),(l()(),e.Na(525,0,null,null,1,"h5",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Zoom liveness check"])),(l()(),e.Na(527,0,null,null,0,"img",[["alt",""],["src","assets/images/2-layers.9.png"]],null,null,null,null,null)),(l()(),e.Na(528,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Zoom liveness analyzes optical flow and perspective distortion. The idea is to look at the same face from multiple distances (by putting the camera closer to the face, or moving it further) and predict if the face is of real person or is a spoof planar picture."])),(l()(),e.Na(530,0,null,null,44,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(531,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["This liveness type is designed for mobile phones, and the results may be erroneous on other platforms."])),(l()(),e.Na(533,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Smile liveness check"])),(l()(),e.Na(535,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["This scenario requires user to smile until the probability calculated by neural network will be above the set threshold."])),(l()(),e.Na(537,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Infrared liveness check"])),(l()(),e.Na(539,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["This scenario requires user to normally appear in front of a NIR camera until the probability calculated by neural network will reach the set threshold."])),(l()(),e.Na(541,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Unified liveness check"])),(l()(),e.Na(543,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Unified liveness combines previous types algorithms with an exception of zoom and blink types, and performs additional calculation and analysis in order to detect fraud attempts."])),(l()(),e.Na(545,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Calculated and tracked entities:"])),(l()(),e.Na(547,0,null,null,15,"ul",[],null,null,null,null,null)),(l()(),e.Na(548,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(549,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["angles"])),(l()(),e.Na(551,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(552,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["mouth landmarks distance"])),(l()(),e.Na(554,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(555,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["eyebrow landmarks distance"])),(l()(),e.Na(557,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(558,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["eye states (blinks)"])),(l()(),e.Na(560,0,null,null,2,"li",[],null,null,null,null,null)),(l()(),e.Na(561,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["smile probability"])),(l()(),e.Na(563,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Complex liveness check"])),(l()(),e.Na(565,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["These liveness types require additional unordinary data for analysis. Such data cannot be obtained by common RGB camera, so it requires the use of complementary devices for its operation."])),(l()(),e.Na(567,0,null,null,1,"h6",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Depth liveness check"])),(l()(),e.Na(569,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Depth liveness requires 16-bit depth matrix sensor, which transfers information relating to the distance of the surfaces of scene objects from a viewpoint in millimeters. "])),(l()(),e.Na(571,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["For correct operation face should be positioned at a distance of 0.5 to 4.5 meters to the sensor."])),(l()(),e.Na(573,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["This liveness type does not require any actions because it performs depth map face region of interest analysis using neural networks."])),(l()(),e.Na(575,0,null,null,23,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(576,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(577,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(578,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Track Engine"])),(l()(),e.Na(580,0,null,null,18,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(581,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Track Engine is a tool for face detection and tracking on multiple sources. It allows to pick the face images most suitable for facial recognition from a sequence of video frames."])),(l()(),e.Na(583,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Track Engine itself does not perform any facial recognition. Its purpose is to prepare required face data for LUNA SDK Descriptor facility methods and LUNA PLATFORM."])),(l()(),e.Na(585,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["The main interface to Track Engine is Stream - an entity to which you submit video frames."])),(l()(),e.Na(587,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["You can create multiple streams at once if required (in cases when you would like to track faces on multiple cameras). In each stream the engine detects faces and builds their tracks. Each face track has its own unique identifier. It is therefore possible to group face images belonging to the same person with their track IDs. Tracks may break from time to time either due to people leaving the surveillance area or due to the challenging detection conditions (poor image quality, occlusions, extreme head poses, etc.)."])),(l()(),e.Na(589,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["The frames are submitted on a one by one basis and each frame has its own unique ID."])),(l()(),e.Na(591,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Track Engine emits various events to inform you about what is happening. The events occur on a per-stream basis."])),(l()(),e.Na(593,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["By implementing one or several observer interfaces it is possible to define custom processing logic in your application."])),(l()(),e.Na(595,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Track Engine allows users to define custom recognition suitability criteria for face detections. That way one may alter the best shot selection logic and, therefore, specify which images will make it to the recognition phase."])),(l()(),e.Na(597,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Track Engine is multi-threaded. The number of threads is configurable and depends on the currently bound LUNA SDK settings."])),(l()(),e.Na(599,0,null,null,7,"div",[["class","row article"]],null,null,null,null,null)),(l()(),e.Na(600,0,null,null,0,"div",[["class","line"]],null,null,null,null,null)),(l()(),e.Na(601,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(602,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Licensing"])),(l()(),e.Na(604,0,null,null,2,"div",[["class","col-lg-12"]],null,null,null,null,null)),(l()(),e.Na(605,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["LUNA SDK comes in multiple editions on all major platforms. Customers are free to pick the one that fits best. In addition, a fine-grained licensing of individual features is possible upon request."])),(l()(),e.Na(607,0,null,null,9,"div",[["class","container-blue"]],null,null,null,null,null)),(l()(),e.Na(608,0,null,null,8,"div",[["class","container-width"]],null,null,null,null,null)),(l()(),e.Na(609,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["We will be happy to share our broad industry experience in implementing efficient Computer Vision solutions and show our Products in action "])),(l()(),e.Na(611,0,null,null,0,"img",[["alt",""],["src","assets/images/-e-Rectangle_3459.png"]],null,null,null,null,null)),(l()(),e.Na(612,0,null,null,4,"div",[["class","buttons"]],null,null,null,null,null)),(l()(),e.Na(613,0,null,null,1,"button",[["class","first"]],null,null,null,null,null)),(l()(),e.cb(-1,null,["Tell me more"])),(l()(),e.Na(615,0,null,null,1,"button",[["class","second"]],null,null,null,null,null)),(l()(),e.cb(-1,null,["Request free Demo"])),(l()(),e.Na(617,0,null,null,5,"div",[["class","container-image"]],null,null,null,null,null)),(l()(),e.Na(618,0,null,null,4,"div",[["class","container-width"]],null,null,null,null,null)),(l()(),e.Na(619,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.cb(-1,null,["Learn more about LUNA PLATFORM application scenarios"])),(l()(),e.Na(621,0,null,null,1,"span",[],null,null,null,null,null)),(l()(),e.Na(622,0,null,null,0,"i",[["class","fas fa-angle-right"]],null,null,null,null,null))],null,null)}var w=e.Ja("app-luna-sdk",a,function(l){return e.db(0,[(l()(),e.Na(0,0,null,null,1,"app-luna-sdk",[],null,null,null,y,_)),e.Ma(1,114688,null,0,a,[],null,null)],function(l,n){l(n,1,0)},null)},{},{},[]);u.d(n,"ProductsModuleNgFactory",function(){return k});var k=e.Ka(s,[],function(l){return e.Ua([e.Va(512,e.j,e.Aa,[[8,[r.a,b,N,P,x,w]],[3,e.j],e.w]),e.Va(4608,g.l,g.k,[e.t,[2,g.x]]),e.Va(1073742336,g.b,g.b,[]),e.Va(1073742336,p.m,p.m,[[2,p.s],[2,p.k]]),e.Va(1073742336,s,s,[]),e.Va(1024,p.i,function(){return[[{path:"",children:[{path:"",component:c},{path:"face-dj",component:i},{path:"luna-cars",component:o},{path:"luna-platform",component:t},{path:"luna-sdk",component:a}]}]]},[])])})}}]);